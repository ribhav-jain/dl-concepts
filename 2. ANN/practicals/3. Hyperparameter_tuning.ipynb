{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN)\n",
    "\n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  - The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  - A common practice is to start with 1-2 hidden layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.3.0\n",
      "  Obtaining dependency information for scikit-learn==1.3.0 from https://files.pythonhosted.org/packages/77/85/bff3a1e818ec6aa3dd466ff4f4b0a727db9fdb41f2e849747ad902ddbe95/scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.3.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn==1.3.0) (3.6.0)\n",
      "Using cached scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.6.1\n",
      "    Uninstalling scikit-learn-1.6.1:\n",
      "      Successfully uninstalled scikit-learn-1.6.1\n",
      "Successfully installed scikit-learn-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.13.0 requires scikit-learn>=1.4.2, but you have scikit-learn 1.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikeras) (3.4.1)\n",
      "Collecting scikit-learn>=1.4.2 (from scikeras)\n",
      "  Obtaining dependency information for scikit-learn>=1.4.2 from https://files.pythonhosted.org/packages/a1/a6/c5b78606743a1f28eae8f11973de6613a5ee87366796583fb74c67d54939/scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (1.24.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (0.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras) (23.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from optree->keras>=3.2.0->scikeras) (4.7.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ribhav.jain\\appdata\\local\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.0)\n",
      "Using cached scikit_learn-1.6.1-cp311-cp311-win_amd64.whl (11.1 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.3.0\n",
      "    Uninstalling scikit-learn-1.3.0:\n",
      "      Successfully uninstalled scikit-learn-1.3.0\n",
      "Successfully installed scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data[\"Gender\"] = label_encoder_gender.fit_transform(data[\"Gender\"])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[[\"Geography\"]]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(\n",
    "    geo_encoded, columns=onehot_encoder_geo.get_feature_names_out([\"Geography\"])\n",
    ")\n",
    "\n",
    "data = pd.concat([data.drop(\"Geography\", axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop(\"Exited\", axis=1)\n",
    "y = data[\"Exited\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open(\"label_encoder_gender.pkl\", \"wb\") as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open(\"onehot_encoder_geo.pkl\", \"wb\") as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "\n",
    "def create_model(neurons=32, layers=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation=\"relu\"))\n",
    "\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps a Keras model to make it compatible with scikit-learn API\n",
    "# - Useful for using tools like GridSearchCV, cross_val_score, etc.\n",
    "# - 'build_fn' is the function that creates and returns the Keras model\n",
    "# - 'layers' and 'neurons' are custom hyperparameters passed to build_fn\n",
    "# - 'verbose=1' enables progress output during training\n",
    "model = KerasClassifier(layers=1, neurons=32, build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "param_grid = {\"neurons\": [16, 32, 64, 128], \"layers\": [1, 2], \"epochs\": [50, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3, verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
